#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\series bold
Detecting Insults In Social Commentary
\end_layout

\begin_layout Author
James Osgood, Clinton Pahl, Paul Vandermeer
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
Abstract
\end_layout

\begin_layout Standard

Insults and abuse on the Internet is becoming a growing problem as we become
 increasingly connected.
 Anonymity and a lack of supervision has led to an increasing number of
 insults in forums that try to promote communication.
 An accurate single-class classifier operating in real-time could automate
 or facilitate the removal of a large number of these insults.
 We would no longer have to completely rely on moderators or the user-base
 to expunge every insult, which will hopefully lead the way to more abuse-free
 discourse on the Internet.
 
\end_layout

\begin_layout Section
Problem
\end_layout

\begin_layout Standard
The goal is to create a single-class classifier that can determine if a
 comment that has been addressed to another person in a blog/forum conversation
 is insulting.
 The predictions are in the range 
\begin_inset Formula $\left[0,1\right]$
\end_inset

 where 1 indicates 100% confidence that the comment was insulting.
 We will only be looking at comments that are addressing other participants
 in the conversation.
 We will consider insults that have been addressed to non-participants (such
 as celebrities, politicians, or other well known public figures) to be
 non insulting for the purposes of this problem.
 We will also have to account for a wide range of possible insults which
 may or may not contain profanity, racial slurs, or other offensive language.
 In addition, a comment that contains offensive language, but is not insulting
 to another participant in the conversation will not be considered insulting.
 Also, the insults that we are attempting to classify will not be subtle
 (such as insults using sarcasm, or Internet memes).
\end_layout

\begin_layout Standard
The data set that we are using comes from a machine learning competition
 on Kaggle
\begin_inset CommandInset citation
LatexCommand cite
key "Im12detectinginsults"

\end_inset

: a website that hosts predictive modeling competitions.
 The data set consists of a training set containing 3948 entries and testing
 set containing 2648 entries.
 Each entry in the training and testing set has a time attribute in the
 form 
\begin_inset Quotes eld
\end_inset

YYYYMMDDhhmmss
\begin_inset Quotes erd
\end_inset

, and the corresponding comment.
 The time is on a 24 hour clock corresponding to when the comment was made.
 The comments are mostly English language comments, compiled from various
 forums with very little formatting.
 Spelling and grammatical errors are very common, and sometimes may even
 contain HTML markup.
 Preprocessing this data to get useful features will be a very important
 step towards accurately classifying insults.
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
Literature Survey
\end_layout

\begin_layout Standard
After searching the Internet we found ten sites
\begin_inset Foot
status open

\begin_layout Plain Layout
The 10 research articles we found are located in the references below.
 
\end_layout

\end_inset

 that have done existing work on our problem and most of our approaches.
 Existing work that has already been done on our problem consists of tree
 structures along with different strategies for preprocessing the data.
 Our literature survey will be examining four articles: 
\begin_inset Quotes eld
\end_inset

Modeling the Detection of Textual Cyber Bullying
\begin_inset Quotes erd
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Li11modelingthe"

\end_inset

, 
\begin_inset Quotes eld
\end_inset

Detecting Offensive Language in Social Media to Protect Adolescent On-line
 Safety(Bullying in Barcelona)
\begin_inset Quotes erd
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Ch12detectingoffensive"

\end_inset

, 
\begin_inset Quotes eld
\end_inset

Big Data as a Tool for Detecting (and punishing?) Bullies
\begin_inset Quotes erd
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Ow12profanityuse"

\end_inset

, and 
\begin_inset Quotes eld
\end_inset

Offensive Language Detection Using Multi-level Classification
\begin_inset Quotes erd
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Ka12detectingoffensive"

\end_inset

.
 These articles use methods that we felt would be worth investigating for
 approaches that we could apply to our own problem.
\end_layout

\begin_layout Standard
The first publication on Bullying in Barcelona demonstrated how “Each dataset
 was subjected to three operations: removal of stop-words, stemming and
 removal of unimportant sequence of characters.
 Sequences of characters such as ‘@someuser’,’lollllll’,’hahahahaha’, etc.,
 were expunged from the datasets.”
\begin_inset CommandInset citation
LatexCommand cite
key "Li11modelingthe"

\end_inset

.
 We found this particularly useful as we needed to perform similar preprocessing
 steps on our own data set.
 The publication also made some assumptions on sexuality, race and culture,
 and intelligence which adds more fine tuned features to their datasets.
 They stated that these three topics contribute to the validity of correctly
 detecting abuse.
 Their experiment exercised a poly-2 kernel and the popular J48 decision
 tree based classifier which implements a 10-fold cross validation for the
 experiments they performed
\begin_inset CommandInset citation
LatexCommand cite
key "Li11modelingthe"

\end_inset

.
 The results they obtained when using the combined feature set gave them
 61% accuracy with a confidence level of .456 which was beat by using a SVM
 which gave 66.7% accuracy with a confidence level of .653.
 
\end_layout

\begin_layout Standard
The research done by Ying Chen et al.
 in the their article 
\begin_inset Quotes eld
\end_inset

Detecting Offensive Language in Social Media to Protect Adolescent On-line
 Safety
\begin_inset Quotes erd
\end_inset

 also broke down their feature-set and set them into categories
\begin_inset CommandInset citation
LatexCommand cite
key "Ch12detectingoffensive"

\end_inset

.
 Just like the publication on 
\begin_inset Quotes eld
\end_inset

Bullying in Barcelona
\begin_inset Quotes erd
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Li11modelingthe"

\end_inset

 they created a specific feature set that consisted of different style,
 structural and content-specific features
\begin_inset CommandInset citation
LatexCommand cite
key "Ch12detectingoffensive"

\end_inset

.
 Their main feature representation consisted of using a bag-of-words feature
 representation.
 They also used an SVM implementation for learning, and 10-fold cross validation
 to tweak performance.
 Their results showed approximately 60% accuracy.
 
\end_layout

\begin_layout Standard
In the remaining two articles there are two interesting concepts that we
 felt could be applied to our own problem.
 One article states that by discovering different time patterns they were
 able to produce better classification results.
\begin_inset CommandInset citation
LatexCommand cite
key "Ow12profanityuse"

\end_inset

 They found that 
\begin_inset Quotes eld
\end_inset

during the school week
\begin_inset Quotes erd
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Ow12profanityuse"

\end_inset

 there was a higher rate of on-line abuse compared to other times of the
 day.The use of word/phrase frequency was brought up in the last article
 we researched.
 Their accuracy is mentioned to be 
\begin_inset Quotes eld
\end_inset

about 16% better than baseline
\begin_inset Quotes erd
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Ka12detectingoffensive"

\end_inset

 which resulted in their tests having an accuracy of approximately 68%.
\begin_inset CommandInset citation
LatexCommand cite
key "Ka12detectingoffensive"

\end_inset


\end_layout

\begin_layout Standard
With the first two articles seeing successful results with the bag-of-words
 feature set, we decided that this would be a good implementation to use
 in our own project.
 Both papers used SVM and 10-fold cross validation so we decided to also
 use a margin classifier to give us a good baseline for our testing accuracy.
 Although, instead of 10-fold cross validation we chose to implement bootstrappi
ng as we decided that it would perform similarly with lesser complexity.
 When choosing features we also decided to eliminate stop-words, sequence
 characters, word frequency, and the time of day in which the comment was
 posted.
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand nocite
key "Ch10textmining10,Da12cyberbullyingdetection,Ha12bigdata,Wi12levenshteindistance,Wi12bagof,Sc08advancesin,Ow12profanityuse,Na07acomparison,Ma12analyticsfor,Li11modelingthe,Ka12robustdetectio,Ka12detectingoffensive,Im12detectinginsults,Ch12detectingoffensive"

\end_inset


\end_layout

\begin_layout Section
Approach
\end_layout

\begin_layout Standard
Our approach involves a series of stages which include: preprocessing the
 data to remove any “noise” that will prevent us from creating useful features;
 extracting features from the comments, and making use of the provided time
 attribute; bootstrapping to determine the best learner and classifier for
 the generated features, and the best feature representation to use for
 the data set; and finally to use the returned learner and classifier to
 classify insults in the testing set.
 The figure below summarizes our approach.
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "400pt"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename approach.png

\end_inset


\end_layout

\begin_layout Plain Layout

\size scriptsize
Figure 1: A diagram of our approach that involves a series of stages.
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard

\series bold
Preprocessing
\series default
 The comments require a number of preprocessing steps to produce useful
 features.
 Our end goal for the comments is to use the words within each comment as
 the features for the training and testing sets for our learning algorithm.
 The first step involved in our preprocessing stage is to return a list
 of the individual words from each comment in the testing and training set.
 To accomplish this we use a tokenizer implemented by Ryan Kelly
\begin_inset CommandInset citation
LatexCommand cite
key "Ry10pyenchant10"

\end_inset

 which in addition to returning individual words, also removes words and
 characters sequences that would not be useful as features for classifying
 insults (such as HTML markup, email addresses, URL’s, and stop words).
\end_layout

\begin_layout Standard
Once the words we have been tokenized, we spell check each word returned
 from the tokenizer to insure that any misspelled words will be represented
 as the same feature.
 We then use the Levenshtein distance for each misspelled word that has
 been corrected by the spell checker to ensure that the spell checked word
 is similar enough to the original misspelled word to be a useful feature.
 The Levenshtein distance is a simple string metric that is used to measure
 the distance between two strings.
 It represents the number of single character replacements that would be
 needed to change one word into another.
 Mathematically, the Levenshtein distance between two strings a,b is given
 by
\begin_inset Formula $lev_{a,b}(|a|,|b|)$
\end_inset

 where:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
lev_{a,b}(i,j)=\begin{cases}
max(i,j) & ,min(i,j)=0\\
min\begin{cases}
lev_{a,b}(i-1,j)+1\\
lev_{a,b}(i,j-1)+1\\
lev_{a,b}(i-1,j-1)+[a_{i}\neq b_{j}]
\end{cases} & ,else
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
We found that any spell checked word with a Levenshtein distance greater
 than 3 from the original word did not accurately represent the original
 misspelled word.
\end_layout

\begin_layout Standard

\series bold
Feature Selection
\series default
 After the comments have been preprocessed we use the bag-of-words model
 as our feature representation for our testing and training sets.
 In the bag of words model, each of our comments is represented as an unordered
 collection of words, where the frequency of each word is used as a feature
 for the learning algorithm.
 
\end_layout

\begin_layout Standard
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout

\series bold
Example: 
\series default
Below are two sentences that demonstrate the bag-of-words model:
\end_layout

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Box Frameless
position "c"
hor_pos "c"
has_inner_box 1
inner_pos "c"
use_parbox 0
use_makebox 0
width "240pt"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Quotes eld
\end_inset

Hello Dale, Are you drinking water?
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Quotes eld
\end_inset

Why are there different colors of water? Why?
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
With these two sentences we can create a dictionary of distinct words which
 looks like this (we ignore case):
\end_layout

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "220pt"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
1:hello,2:dale,3:are,4:you.5:drinking,6:water,
\end_layout

\begin_layout Plain Layout
7:why,8:there,9:different,10:colors,11:of
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
This dictionary now contains 10 distinct words which gets translated into
 a simple vector of size (1,10) which is now the feature representation
 for each sentence.
 With two sentences you will have a matrix of size (2,10) which will now
 contain the word count at each index of the vector:
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\begin{array}{cccccccccc}
1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0\\
0 & 0 & 1 & 0 & 0 & 1 & 2 & 1 & 1 & 1
\end{array}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
You may notice that after the conversion we increment how many times the
 word has occurred at the index of the word in the dictionary.
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
We found that bag of words generates too many features for each comment
 (~15000).
 So we took an approach that has been commonly used for text classification:
 using only a certain numbers of the most frequent words that occur across
 all comments for the bag of words model.
 Using this method we can choose the number of features (words) that we
 want to represent for the comments.
\end_layout

\begin_layout Standard
In addition to using word frequency for our feature representation, we also
 use the time that the comment was made.
 Specifically we use the day of the week and the hour that the comment was
 made as a binary representation and append it to our word features.
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout

\series bold
Example:
\series default
 Time feature representation
\end_layout

\begin_layout Plain Layout
Lets take the format YYYYMMDDhhmmss from which we use the month(MM) and
 the day(DD) for our feature representation.
 We take this information and represent which day of the week and hour the
 comment was created on.
 We then create a vector of size (31,1) where the first 7 cells represent
 the weekday(s,m,t,w,th,f,s) and the other 24 cells represent the time of
 day.
 Below shows a graphical conversion:
\end_layout

\begin_layout Plain Layout
\noindent
\align center
20121213021300 
\begin_inset Formula $\Longrightarrow$
\end_inset


\begin_inset Formula $\begin{array}{ccccccccccc}
0_{0} & ... & 0_{3} & 1_{4} & 0_{5} & ... & 0_{8} & 1_{9} & 0_{10} & ... & 0_{23}\end{array}$
\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\series bold
Learners
\series default
 To classify the insults, we implement a variety of learners and kernel
 transformations.
 Because the original Kaggle description of the problem requires a probability
 as a result we use a sigmoid loss margin learner as one of our algorithms.
 Specifically, we use the sigmoid transformation
\end_layout

\begin_layout Standard
[equation: 
\begin_inset Formula $\hat{y}=(1+e^{(-\hat{z})})^{-1}$
\end_inset

]
\end_layout

\begin_layout Standard
and the sigmoid loss
\end_layout

\begin_layout Standard
[equation: 
\begin_inset Formula $y*log(\frac{y}{\hat{y}})+(1-y)*log(\frac{1-y}{1-\hat{y}})$
\end_inset

]
\end_layout

\begin_layout Standard
to learn on a probability scale.
 However, to prevent divisions by zero, we provide slight offsets of 1E-6
 to the given y training vector.
 Classification is done using a confidence level at which any result with
 a probability about that level is classified as an insult.
\end_layout

\begin_layout Standard
In addition to the sigmoid-margin learner, we use the log-sum-exp-margin,
 soft-margin, and dual hard-margin algorithms, as implemented in the second
 assignment, so we can compare these classification methods.
 All learners are in their kernelized forms because the large amount of
 features creates prohibitively sized matrices.
 And, all learners are also regularized because the problem statement on
 Kaggle mentions that over-fitting is often an issue.
\end_layout

\begin_layout Standard

\series bold
Kernels
\series default
 We use linear, Gaussian, and bag-of-words kernels in our learners to determine
 the best algorithm for this problem.
 The linear and Gaussian kernels are implemented as in the assignments.
 Our bag-of-words kernels comes in two forms:
\end_layout

\begin_layout Itemize
Binary shared words: the value of similarity between two comments (concerning
 similar words) is the number of words each comments share, not taking into
 account duplicates; this is the equivalent to the linear kernel of a regular,
 binary bag-of-words feature expansion.
\end_layout

\begin_layout Itemize
Count of common shared words: the value of similarity between two comments
 (concerning similar words) is the total number of words the comments have
 in common; that is, for each word the comments share, the total number
 of common words is the minimum of the count of that word in both comments.
\end_layout

\begin_layout Section
Rationale
\end_layout

\begin_layout Standard

\series bold
Preprocessing
\series default
 The preprocessing stage ended up being much more difficult than expected.
 A large number of the comments from the data set have a significant amount
 of grammatical and spelling errors.
 Attempting to use these comments without any preprocessing would have resulted
 in too many features to be of any use for our learning algorithm.
 For example, a word that has been misspelled by just a single character
 such as “lerner” would result in a new feature, when it could instead be
 corrected to use the word “learner” as a common feature instead.
 As a result it was obvious that each comment needed to be spell checked
 in order to reduce the feature space, and to provide more accurate representati
ons of the comments to the learners.
 Similarly it was obvious that we needed to remove words that would tell
 us nothing about about the insulting nature of a comment; otherwise we
 would have a very low frequency among other comments in our data set.
 As a result it was also obvious that we would need to remove any additional
 words or character sequences from our feature space (such as HTML, URL’s,
 email addresses, misspelled acronyms, etc.) with a low frequency among the
 other comments.
\end_layout

\begin_layout Standard
While compiling material for our literature survey we also found that a
 number of previous researchers, such as Karthik Dinakar et al.
\begin_inset CommandInset citation
LatexCommand cite
key "Li11modelingthe"

\end_inset

, were seeing improved results by removing stop words from their documents.
 Luckily we were able to find a tokenizer implemented by Christian Pecci
 
\begin_inset CommandInset citation
LatexCommand cite
key "Ch10textmining10"

\end_inset

 to accomplish this for us.
 Another idea that we use to reduce the feature space is to only keep a
 specified number of the most frequent words that occur across all documents.
 This allows us to drastically reduce the number of features that we are
 using as we were still getting close to 9000 features after tokenizing,
 spell checking, and using the Levenshtein distance.
 From early testing, this original feature space appeared to be too large
 to allow us to make accurate classifications.
\end_layout

\begin_layout Standard
Another subtle issue that we noticed early on is that our spell checker
 would make spelling suggestions that were drastically different than the
 word being spell checked.
 Obviously a corrected word that is drastically different from its original
 meaning would not be a useful feature for classification.
 We solve this issue by using the Levenshtein distance mentioned above by
 discarding any spell checking suggestions that have a distance greater
 than 3 as we noticed that suggested words tend to diverge from their original
 meaning around this value.
\end_layout

\begin_layout Standard
As for coming up for the feature representations for the comments, we wanted
 to use an approach that was relatively simple and intuitive since this
 was our first attempt at converting textual documents to features.
 A number of the papers that we came across used the bag-of-words model
 
\begin_inset CommandInset citation
LatexCommand cite
key "Ch12detectingoffensive"

\end_inset

, and appeared to be getting successful results.
 This approach was very appealing as it was intuitive enough for us to quickly
 understand.
 We also decided to attach time as a feature since it was supplied as an
 attribute in our data set, and we came across some literature that supported
 idea that the frequency of insults is correlated with the time and day
 of the week 
\begin_inset CommandInset citation
LatexCommand cite
key "Ow12profanityuse"

\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Feature Expansion
\series default
 Of all the text transformations used for machine learning purposes, the
 bag-of-words feature expansion was the quickest to implement and the easiest
 to comprehend.
 It did not require a database of words or a very complex algorithm to create
 useful features, and there existed libraries to assist in easy generation
 of a bag-of-words model.
\end_layout

\begin_layout Standard

\series bold
Learners
\series default
 Because we want to compare the accuracy of several approaches to this problem,
 we need a baseline to compare to, and we have experience with these methods.
 The log-sum-exp-margin, soft-margin, and dual hard-margin algorithms are
 used.
 And, because the Kaggle problem statement requires probability, and we
 are concerned with over classifying comments as insults, we feel that the
 sigmoid-margin learner will be more successful than the other binary classifier
s we have studied over the course; the sigmoid transformation is the obvious
 choice for dealing with probabilities.
 Also, because of the size of the feature expansion, using kernels is basically
 required for effective testing.
\end_layout

\begin_layout Standard

\series bold
Kernels
\series default
 The feature expansions we chose dictates, somewhat, the kernels that we
 use in our learners.
 The binary bag-of-words kernel is the classic kernel for the bag-of-words
 feature expansion, but we think that counting the total number of shared
 words may better indicate similarity due to frequency of swear words and
 other insulting terms.
\end_layout

\begin_layout Standard
In addition, the linear and Gaussian kernels are a common baseline, and
 could give us interesting insight into the form of the data if they prove
 useful.
\end_layout

\begin_layout Section
Hypotheses
\end_layout

\begin_layout Standard
After reviewing the documents mentioned in the literature survey it was
 hypothesized that if we combined what we found to be the most useful and
 intuitive methods we would be able to accurately classify a comment as
 insulting.
 We decided to test the following methods:
\end_layout

\begin_layout Standard

\series bold
Bag-of-words features
\series default
 A bag-of-words feature representation of text is simple enough to implement,
 and useful enough to accurately represent similarities between comments.
\end_layout

\begin_layout Standard

\series bold
Removing infrequent words
\series default
 Reducing the total number of words to the top X most frequent words improves
 performance by making the kernel transformations faster.
 It should also get rid of useless features that do not help the learner.
\end_layout

\begin_layout Standard

\series bold
Removing stop words
\series default
 The removal of stop words (such as “you”, “a”, and “if” … ) reduces the
 number of useless features which improves accuracy of learners that use
 bag-of-words features.
 Very common words are probably not that useful in determining if a comment
 is an insult or not.
\end_layout

\begin_layout Standard

\series bold
Levenshtein distance
\series default
 Levenshtein distance is very useful in reducing the probability that the
 spell check preprocessing gives bad replacements of misspelled words, thus
 preventing bad features from being supplied to the learners
\end_layout

\begin_layout Standard

\series bold
Time as a feature
\series default
 Adding the time of day and day of week as weighted features (to provide
 a noticeable difference in the similarity matrices) gives learners additional
 useful features to classify comments.
\end_layout

\begin_layout Standard

\series bold
Kernels
\series default
 The kernel that uses the common count of shared words is an improvement
 over the regular bag-of-words kernel that takes into account only whether
 two comments share a word.
 This kernel is also not significantly slower than the binary bag-of-words
 kernel.
 In addition, the linear and Gaussian kernels are not superior to the bag-of-wor
ds kernels because the feature expansion is suited especially to the bag-of-word
s kernels.
 A Gaussian feature expansion will not produce better results than a linear
 kernel since the data that is being classified is in a very high dimensional
 space and should be easily separable without having to use a feature expansion.
\end_layout

\begin_layout Standard

\series bold
Learners
\series default
 The sigmoid-margin learners are more accurate in determining if a comment
 is an insult.
 Since over-fitting is a significant problem, using a confidence level to
 allow classification of insults is a better solution for this problem than
 relying solely on the beta regularizer.
\end_layout

\begin_layout Section
Experimental Design
\end_layout

\begin_layout Standard
To test the time performance and compare the quality of the various feature
 expansions, kernels, and learners, we ran tests on all the combinations
 of kernels and learners at different levels of feature expansion.
 We used a four pass bootstrapping algorithm to select the best of each
 combination of kernel and learner, in terms of average minimum error, at
 each feature expansion level.
 We also checked the average training time for each algorithm combination
 during bootstrapping.
 To create a useful set of training data, we took an equal amount of randomly
 selected insult and non-insult training data, since the given training
 data was significantly skewed towards non-insult comments.
\end_layout

\begin_layout Standard
We used the following feature expansion levels to test our hypotheses:
\end_layout

\begin_layout Itemize
Our plain bag-of-words model with a Levenshtein distance of 20 (rendered
 the Levenshtein distance almost useless).
 This established a baseline for the bag-of-words feature expansion.
\end_layout

\begin_layout Itemize
The same specifications as the above level, but only using the 3000 most
 frequent words.
\end_layout

\begin_layout Itemize
The same specifications as the above level, but with all stop words removed.
\end_layout

\begin_layout Itemize
The same specifications as the above level, but with a Levenshtein distance
 of 3.
\end_layout

\begin_layout Itemize
The same specifications as the above level, but with time (hour and day
 of week) added as a feature.
\end_layout

\begin_layout Standard
Once we had our five sets of data, we ran the following combinations of
 kernel transformations and learning algorithms on one tenth of each training
 data set (300 entries per set).
\end_layout

\begin_layout Standard
Learners:
\end_layout

\begin_layout Itemize
adjoint log-sum-exp-margin classifier
\end_layout

\begin_layout Itemize
adjoint soft-margin classifier
\end_layout

\begin_layout Itemize
hard-margin classifier
\end_layout

\begin_layout Itemize
sigmoid-margin probability predictor
\end_layout

\begin_layout Standard
Kernels:
\end_layout

\begin_layout Itemize
linear kernel
\end_layout

\begin_layout Itemize
Gaussian kernel with a sigma value of 20
\end_layout

\begin_layout Itemize
binary bag-of-words kernel
\end_layout

\begin_layout Itemize
common word count bag-of-words kernel
\end_layout

\begin_layout Standard
All tests were run with a beta regularizer of 0.5 to deal with over-fitting.
\end_layout

\begin_layout Standard
We ran all the tests on the computers in the Database and AI lab.
\end_layout

\begin_layout Standard
With all this data of each combination of learner and kernel, and each feature
 expansion level, we could determine the speed and accuracy improvements
 between each specification.
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Standard
The following tables display the results seen from the above experiments
 specified in “Experimental Design”.
 Each column lists the loss (misclassification errors) and the running time
 (in seconds) for the corresponding learning algorithms.
 Subsets of 300 training inputs containing an equal number of insults and
 non-insults were used by the bootstrapping algorithm to produce the following
 results:
\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "402pt"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout

\size scriptsize
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="7">
<features booktabs="true" islongtable="true" longtabularalignment="center">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<row endhead="true">
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
adj lse-margin
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
adj soft-margin
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid linear
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid gauss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid min
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid binary
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
loss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
N/A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
N/A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
N/A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
N/A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
N/A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
N/A
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
duration
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
N/A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
N/A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
N/A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
N/A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
N/A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
N/A
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout

\size scriptsize
Table 1: Result of learners run on a data set using the following features
 and preprocessing steps: Bag-of-words.
 This test was taking an unreasonable amount of time and was canceled before
 it could complete.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "402pt"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout

\size scriptsize
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="7">
<features booktabs="true" islongtable="true" longtabularalignment="center">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<row endhead="true">
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
adj lse-margin
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
adj soft-margin
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid linear
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid gauss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid min
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid binary
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
loss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
.3562
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
.4658
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
.4521
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
.5342
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
.3562
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
.3972
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
duration
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
2019.3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
54.5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
16.0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
12.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
412.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
17168.5
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout

\size scriptsize
Table 2: Result of learners run on a data set using the following features
 and preprocessing steps: 
\end_layout

\begin_layout Plain Layout

\size scriptsize
Bag-of-words; 3000 most frequent bag-of-words features.
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "402pt"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout

\size scriptsize
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="7">
<features booktabs="true" islongtable="true" longtabularalignment="center">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<row endhead="true">
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
adj lse-margin
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
adj soft-margin
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid linear
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid gauss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid min
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid binary
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
loss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
0.4569
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
0.5147
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
0.2647
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
0.3676
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
0.2647
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
0.2647
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
duration
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
3672.95
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
68.78
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
12.79
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
12.73
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
400.73
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
392.00
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout

\size scriptsize
Table 3: Result of learners run on a data set using the following features
 and preprocessing steps: 
\end_layout

\begin_layout Plain Layout

\size scriptsize
Bag-of-words; 3000 most frequent bag-of-words features; stop words removed.
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "402pt"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout

\size scriptsize
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="7">
<features booktabs="true" islongtable="true" longtabularalignment="center">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<row endhead="true">
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
adj lse-margin
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
adj soft-margin
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid linear
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid gauss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid min
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid binary
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
loss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
0.3375
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
0.4375
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
0.3875
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
0.5625
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
0.3750
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
0.3875
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
duration
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
5496.47
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
152.8
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
32.8
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
32.5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
452.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
444.9
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout

\size scriptsize
Table 4: Result of learners run on a data set using the following features
 and preprocessing steps: 
\end_layout

\begin_layout Plain Layout

\size scriptsize
Bag-of-words; 3000 most frequent bag-of-words features; stop words removed;
 Levenshtein distance of 3.
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "402pt"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout

\size scriptsize
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="7">
<features booktabs="true" islongtable="true" longtabularalignment="center">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<row endhead="true">
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
adj lse-margin
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
adj soft-margin
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid linear
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid gauss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid min
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid binary
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
loss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
.4375
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
.4375
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
.4250
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
.5875
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
.4125
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
.4250
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
duration
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
2428.3748
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
54.2783
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
27.8204
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
27.7552
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
424.3826
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
425.8133
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout

\size scriptsize
Table 5: Result of learners run on a data set using the following features
 and preprocessing steps: 
\end_layout

\begin_layout Plain Layout

\size scriptsize
Bag-of-words; 3000 most frequent bag-of-words features; stop words removed;
 Levenshtein distance of 3; time features added.
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
And finally, to test our learner and data set more concretely we did one
 final test containing 2000 training inputs and 1000 test inputs each containing
 an equal number of of insults and non-insults.
 It was not definitive which combination of learner and data set was best
 from our bootstrapping results so we decided to run the final test on the
 data set used to get the results in the 4th table with the sigmoid learner
 with a linear kernel since it produced good results in a reasonable time:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "105pt"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="2">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0pt">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
sigmoid linear
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
loss
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2599
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size scriptsize
duration
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2426.4
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Critical Evaluation
\end_layout

\begin_layout Standard
The results returned from our experiments definitely answered some of the
 questions raised in our hypotheses, but at the same time provided some
 very unclear and unintuitive results.One question that appears to have been
 answered definitively is that the bag-of-words feature representation can
 in fact be used to accurately represent the similarities between comments.
 We were able to produce results that were substantially better than random
 choice across every data set.
\end_layout

\begin_layout Standard
From the second table we were also able to show that by keeping only a certain
 number of the most frequent bag-of-word features, we were able to significantly
 increase the performance of the learning algorithms in comparison to the
 first test that used an unmodified bag-of-words feature representation
 which.
 This test was not able to complete in a reasonable time -- most likely
 because there we simply too many features for the kernelized version to
 provide the learner with useful similarities between each entry in the
 training set.
\end_layout

\begin_layout Standard
The third table shows a surprisingly unintuitive result: using the Levenshtein
 distance to remove poor spell checking suggestions both increased the running
 time and the loss returned from the sigmoid learning algorithms.
 This result is surprising because the Levenshtein distance should have
 strengthened the words being returned for the bag-of-words feature representati
on by creating a clearer similarity between both insulting and non-insulting
 comments.
 One possible reason for this result could in fact be due to the data set
 that we used for the five separate experiments.
 The data set across all five experiments consisted of 300 entries containing
 an equal number of insults and non-insults, but we made one unforeseen
 mistake while setting up these experiments: each data set of 300 entries
 was randomly generated for each experiment.
 In retrospect, using five different randomly generated data sets did not
 allow us to evaluate our hypotheses as accurately as if we had used the
 same data set across all five experiments.
 The discrepancy in the loss between tables 3 and 4 is still somewhat surprising
, but can also be explained by the relatively small training size.
 Given more time, we should supply a larger data set to our bootstrapping
 algorithm to generate more concrete results.
\end_layout

\begin_layout Standard
The same issue was seen for the data set containing the time features.
 This can be explained by the same reasoning as above, or it could simply
 be that there is no relevant correlation between the frequency of insults
 and the time of day.
 We are still convinced that there will be some correlation, and would require
 more testing to investigate this further.
 One possible refinement could be to make the feature more discreet: instead
 of using hours of the day, we could indicate whether the comment occurred
 during the morning, afternoon, or evening which could more clearly reflect
 people’s commenting habits.
\end_layout

\begin_layout Standard
It is also clear from the tables above that the Gaussian kernel was not
 useful for classifying the given data, and in most cases tended to over-fit
 resulting in classifications that were worse than random choice.
 Since over-fitting did appear to be somewhat of a problem, using a confidence
 interval did allow us to produce better results in some cases.
 Although the results were not conclusive enough to determine if that approach
 is the best choice, and some additional testing on larger data sets would
 be needed to conclusively determine if it’s more effective to use a confidence
 interval.
\end_layout

\begin_layout Section
Lessons Learned
\end_layout

\begin_layout Standard
When we first started planning on how to generate features, we greatly underesti
mated how difficult and finicky it would be.
 We ended up enhancing our preprocessing steps and bag-of-words feature
 representations several times in order to provide the best possible features
 to our learners.
 It did not take us long to come to the realization that generating text
 from features is a difficult problem that does not appear to have a common
 solution.
 Our choice of the bag-of-words model was a decent choice, but it takes
 a significant amount of preprocessing to be usable which in itself is very
 difficult.
 With more dedicated time, we would have explored some additional feature
 representations that we came across in our literature survey.
 It would have been interesting to venture into tree implementations such
 as Bayesian additive regression trees(BART)
\begin_inset CommandInset citation
LatexCommand cite
key "Na07acomparison"

\end_inset

, classification and regression trees(CART)
\begin_inset CommandInset citation
LatexCommand cite
key "Na07acomparison"

\end_inset

, and J48
\begin_inset CommandInset citation
LatexCommand cite
key "Li11modelingthe"

\end_inset

.
 The String Kernel would have also been useful to implement as it is supposed
 to work well with large datasets, and seems to be very popular in research
 fields of text and gene analysis
\begin_inset CommandInset citation
LatexCommand cite
key "Wi12StringKernel"

\end_inset

.
 Other features that could have been useful to implement might have been:
 sentence length, type of punctuations, sentence appearance(UPPERCASE for
 yelling), imperative sentences, appearance of offensive words, and the
 more content-specific features such as race, religion, etc...
\begin_inset CommandInset citation
LatexCommand cite
key "Ch12detectingoffensive"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "bibtex"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
