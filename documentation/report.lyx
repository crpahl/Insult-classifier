#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title

\series bold
Detecting Insults In Social Commentary
\end_layout

\begin_layout Author
James Osgood, Clinton Pahl, Paul Vandermeer
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
Abstract
\end_layout

\begin_layout Standard
(present tense)
\end_layout

\begin_layout Standard
Insults and abuse on the internet is becoming a growing problem as we become
 increasingly connected.
 Anonymity and a lack of supervision has led to an increasing number of
 insults in forums that try to promote communication.
 An accurate single-class classifier operating in real-time could automate
 or facilitate the removal of a large number of these insults.
 We would no longer have to completely rely on moderators or the user-base
 to expunge every insult which will hopefully lead the way to more abuse-free
 discourse on the internet.
 
\end_layout

\begin_layout Section
Problem
\end_layout

\begin_layout Standard
(present tense)
\end_layout

\begin_layout Standard
The goal is to create a single-class classifier that can determine if a
 comment that has been addressed to another person in a blog/forum conversation
 is insulting.
 The predictions are in the range 
\begin_inset Formula $\left[0,1\right]$
\end_inset

 where 1 indicates 100% confidence that the comment was insulting.
 We will only be looking at comments that are addressing other participants
 in the conversation.
 We will consider insults that have been addressed to non-participants (such
 as celebrities, politicians, or other well known public figures) to be
 non insulting for the purposes of this problem.
 We will also have to account for a wide range of possible insults which
 may or may not contain profanity, racial slurs, or other offensive language.
 In addition, a comment that contains offensive language, but is not insulting
 to another participant in the conversation will not be considered insulting.
 Also, The insults that we are attempting to classify will not be subtle
 (such as insults using sarcasm, or internet memes).
\end_layout

\begin_layout Standard
The data set that we are using comes from a machine learning competition
 on Kaggle
\begin_inset CommandInset citation
LatexCommand cite
key "Im12detectinginsults"

\end_inset

: a website that hosts predictive modeling competitions.
 The data set consists of a training and testing set.
 Each entry in the training and testing set has a time attribute in the
 form 
\begin_inset Quotes eld
\end_inset

YYYMMDDhhmmss
\begin_inset Quotes erd
\end_inset

, and the corresponding comment.
 The time is on a 24 hour clock corresponding to when the comment was made.
 The comments are mostly english language comments, compiled from various
 forums with very little formatting.
 Spelling and grammatical errors are very common, and sometimes may even
 contain html markup.
 Preprocessing this data to get useful features will be a very important
 step towards accurately classifying insults.
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
Literature Survey
\end_layout

\begin_layout Standard
After searching the Internet we found ten sites that have done a study on
 the same topic or very close to the same topics.
 Existing work that has already been done on our problem consists of using
 different kinds of tree structures along with several different ways of
 preprocessing the data.
 Our literature survey will be mention four articles: Modeling the Detection
 of Textual Cyber bullying
\begin_inset CommandInset citation
LatexCommand cite
key "Li11modelingthe"

\end_inset

, Detecting Offensive Language in Social Media to Protect Adolescent On-line
 Safety(Bullying in Barcelona)
\begin_inset CommandInset citation
LatexCommand cite
key "Ch12detectingoffensive"

\end_inset

, Big data as a tool for detecting (and punishing?) bullies
\begin_inset CommandInset citation
LatexCommand cite
key "Ow12profanityuse"

\end_inset

, and Offensive Language Detection Using Multi-level Classification
\begin_inset CommandInset citation
LatexCommand cite
key "Ka12detectingoffensive"

\end_inset

.
 These articles use methods that are interesting and worth investigating.
\end_layout

\begin_layout Standard
The first publication on Bullying in Barcelona demonstrated how “Each dataset
 was subjected to three operations: removal of stop-words, stemming and
 removal of unimportant sequence of characters.
 Sequences of characters such as ‘@someuser’,’lollllll’,’hahahahaha’, etc.,
 were expunged from the datasets.”
\begin_inset CommandInset citation
LatexCommand cite
key "Li11modelingthe"

\end_inset

.
 The publication also made some assumptions on sexuality, race and culture,
 and intelligence which adds more fine tuning features to their preprocessing
 of the datasets.
 Stating that these three topics contribute to the validity of correctly
 detecting abuse.
 Their experiment exercised a poly-2 kernel and the popular J48 decision
 tree based classifier which implements a 10-fold cross validation for the
 experiments they performed.
\begin_inset CommandInset citation
LatexCommand cite
key "Li11modelingthe"

\end_inset

 The results they obtained when using the combined feature set gave them
 61% accuracy with a confidence level of .456 which was beat by using SVM
 which the results of 66.7% accuracy with a confidence level of .653.
 So to conclude their research showed that the SVM was proven to be the
 most reliable as it had the higher confidence level.
 
\end_layout

\begin_layout Standard
The research done by Ying Chen, Heng Xu, Heng Xu in the their article called
 
\begin_inset Quotes eld
\end_inset

Detecting Offensive Language in Social Media to Protect Adolescent On-line
 Safety
\begin_inset Quotes erd
\end_inset

 broke down more features and set them into categories.
\begin_inset CommandInset citation
LatexCommand cite
key "Ch12detectingoffensive"

\end_inset

 Just like the publication on 
\begin_inset Quotes eld
\end_inset

Bullying in Barcelona
\begin_inset Quotes erd
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Li11modelingthe"

\end_inset

 they created a specific feature set that consisted different style, structural
 and content-specific features.
\begin_inset CommandInset citation
LatexCommand cite
key "Ch12detectingoffensive"

\end_inset

 Their methods consists of using Bag of Words for preprocessing, as well
 as SVM and 10-fold cross validation.
 Their results consisted about ~60% return on their learner.
 
\end_layout

\begin_layout Standard
In the remaining two articles there interesting points which 1) states that
 discovering different time patterns they were able to get better detection
 results.
\begin_inset CommandInset citation
LatexCommand cite
key "Ow12profanityuse"

\end_inset

 They found that 
\begin_inset Quotes eld
\end_inset

during the school week
\begin_inset Quotes erd
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Ow12profanityuse"

\end_inset

 there was way more on-line abuse compared to other times.
 2) The use of word/phrase frequency was brought up in the last article
 we researched.
 Their accuracy is mentioned to be 
\begin_inset Quotes eld
\end_inset

about 16% better than baseline
\begin_inset Quotes erd
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Ka12detectingoffensive"

\end_inset

 which has an accuracy of approximately 68%.
\begin_inset CommandInset citation
LatexCommand cite
key "Ka12detectingoffensive"

\end_inset


\end_layout

\begin_layout Standard
With the first two articles choosing to use bag of words we thought it was
 of best interest to implement a method of our own.
 Both papers used SVM and 10-fold cross validation so we decided to go ahead
 with SVM, but instead of 10-fold cross validation we chose to implement
 bootstrapping as we thought it would perform better with lesser complexity.
 When choosing features we also decided to eliminate stop-words, sequence
 characters, word frequency, and the time of day in which the comment was
 posted.
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand nocite
key "Ch10textmining10,Da12cyberbullyingdetection,Ha12bigdata,Wi12levenshteindistance,Wi12bagof,Sc08advancesin,Ow12profanityuse,Na07acomparison,Ma12analyticsfor,Li11modelingthe,Ka12robustdetectio,Ka12detectingoffensive,Im12detectinginsults,Ch12detectingoffensive"

\end_inset


\end_layout

\begin_layout Section
Approach
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename approach.png

\end_inset


\end_layout

\begin_layout Standard
(present tense)
\end_layout

\begin_layout Section
Rationale
\end_layout

\begin_layout Standard
(present tense)
\end_layout

\begin_layout Section
Hypotheses
\end_layout

\begin_layout Standard
A bag-of-words feature representation of text is simple enough to implement
 and useful enough to accurately represent similarities between comments.
 Certain transformations may be necessary to deal with spelling issues and
 common words.
 In addition, a count of the number of each word in a comment, rather than
 just a binary yes or no of a word's presence in a comment, better demonstrates
 similarities between the text.
\end_layout

\begin_layout Standard
The kernel that uses the common count of shared words is an improvement
 over the regular bag-of-words kernel that takes into account only whether
 two comments share a word.
 This kernel is also not significantly slower than the binary bag-of-words
 kernel.
\end_layout

\begin_layout Standard
Using a sigmoid-margin learner to predict probabilities, then classifying
 with a certain confidence level, separates the data with less misclassification
s than using traditional binary classifiers such as log-sum-exp-margin and
 hard-margin.
 Since overfitting is a significant problem, using a confidence level to
 allow classification of insults is a better solution for this problem than
 relying solely on the adjustment of a beta regularizer.
\end_layout

\begin_layout Section
Experimental Design
\end_layout

\begin_layout Standard
To test the time performance and compare the quality of the common word
 count bag-of-word kernel to the binary bag-of-words kernel, we ran tests
 on several learners using both kernels, in addition to the linear and gaussian
 kernel.
 We used a 4 pass bootstrapping algorithm to select the best of each combination
 of kernel and learner, in terms of minimum error.
 Using this process we also determined whether the sigmoid-margin classifier
 had better results than the binary classifiers.
 We also checked the average training time for each algorithm combination
 during bootstrapping.
\end_layout

\begin_layout Standard
We ran the following combinations of kernel transformations and learning
 algorithms with one tenth of the training data (250 entries).
\end_layout

\begin_layout Standard
Learners:
\end_layout

\begin_layout Itemize
adjoint log-sum-exp-margin classifier
\end_layout

\begin_layout Itemize
adjoint soft-margin classifier
\end_layout

\begin_layout Itemize
hard-margin classifier
\end_layout

\begin_layout Itemize
sigmoid-margin probability predictor
\end_layout

\begin_layout Standard
Kernels:
\end_layout

\begin_layout Itemize
linear kernel
\end_layout

\begin_layout Itemize
gaussian kernel with a sigma value of 20
\end_layout

\begin_layout Itemize
binary bag-of-words kernel
\end_layout

\begin_layout Itemize
common word count bag-of-words kernel
\end_layout

\begin_layout Standard
All tests were run with a beta regularizer of 0.5 to deal with overfitting.
\end_layout

\begin_layout Standard
We ran all the tests on the computers in the Database and AI lab.
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Standard
(past tense)
\end_layout

\begin_layout Standard
The combinations of the linear kernel and common word count bag-of-words
 kernel with the adjoint log-sum-exp-margin classifier since the Matlab
 optimizers could not solve these problems without crashing.
 Additionally, both bag-of-words kernels did not complete after 3 hours
 of time 
\end_layout

\begin_layout Section
Critical Evaluation
\end_layout

\begin_layout Standard
(present tense)
\end_layout

\begin_layout Section
Lessons Learned
\end_layout

\begin_layout Standard
(present tense)
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "bibtex"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
